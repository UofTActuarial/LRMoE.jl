var documenterSearchIndex = {"docs":
[{"location":"examples/sim_fit/simulate_fit/#Introduction","page":"Fitting Function","title":"Introduction","text":"","category":"section"},{"location":"examples/sim_fit/simulate_fit/","page":"Fitting Function","title":"Fitting Function","text":"This document contains the data fitting process for the demo dataset included in the LRMoE.jl package.  This serves as an example of using the main fitting function fit_LRMoE included in the package.","category":"page"},{"location":"examples/sim_fit/simulate_fit/","page":"Fitting Function","title":"Fitting Function","text":"# Load data\n@load \"X_obs.jld2\" X_obs\n@load \"Y_obs.jld2\" Y_obs","category":"page"},{"location":"examples/sim_fit/simulate_fit/#Fitting-LRMoE","page":"Fitting Function","title":"Fitting LRMoE","text":"","category":"section"},{"location":"examples/sim_fit/simulate_fit/","page":"Fitting Function","title":"Fitting Function","text":"In this section, we demonstrate how to fit an LRMoE model in the package.  In the current version of LRMoE, the minimal inputs required from the user are:  response, covariates, initialization of logit regression coeffecients and component distributions.","category":"page"},{"location":"examples/sim_fit/simulate_fit/","page":"Fitting Function","title":"Fitting Function","text":"# Assume a non-informative guess\nα_guess = fill(0.0, 2, 5)\n# Correctly specified component distributions\nmodel_guess = [PoissonExpert(10.0) ZIGammaCountExpert(0.50, 40, 0.80);\n               LogNormalExpert(3.0, 1.0) InverseGaussianExpert(15.0, 15.0)]","category":"page"},{"location":"examples/sim_fit/simulate_fit/","page":"Fitting Function","title":"Fitting Function","text":"Now we are ready to call the fitting function. It is optional to print out intermediate updates of parameters. ","category":"page"},{"location":"examples/sim_fit/simulate_fit/","page":"Fitting Function","title":"Fitting Function","text":"result_1 = fit_LRMoE(Y_obs, X_obs, α_guess, model_guess)","category":"page"},{"location":"examples/sim_fit/simulate_fit/","page":"Fitting Function","title":"Fitting Function","text":"The fitted model can be viewed as follows.","category":"page"},{"location":"examples/sim_fit/simulate_fit/","page":"Fitting Function","title":"Fitting Function","text":"summary(result_1)","category":"page"},{"location":"examples/sim_fit/simulate_fit/","page":"Fitting Function","title":"Fitting Function","text":"Model: LRMoE\nFitting converged after 7 iterations\nDimension of response: 2\nNumber of components: 2\nLoglik: -73153.32112999677\nLoglik (no penalty): -73147.35233984645\nAIC: 146320.7046796929\nBIC: 146414.22545854456\nFitted α:\n[-0.4317549468937167 1.0687536487401863 -0.0501666562042898 0.0951104899516\n9831 1.1966666208577514; 0.0 0.0 0.0 0.0 0.0]\nFitted component distributions:\nAnyExpert{LRMoE.NonNegative,z,d} where d<:(Distribution{Univariate,S} where\n S<:ValueSupport) where z<:ZeroInflation[PoissonExpert{Float64}(6.016755579\n291526) ZIGammaCountExpert{Float64}(0.2061960764035149, 29.956369104025327,\n 0.4888535921075801); LogNormalExpert{Float64}(4.001049211038016, 0.2967339\n201031063) InverseGaussianExpert{Float64}(20.303659308753492, 21.7568654316\n48063)]","category":"page"},{"location":"examples/sim_fit/simulate_fit/","page":"Fitting Function","title":"Fitting Function","text":"More specifically, the fitted logit regression coefficients and component distributions are given below. We see that the fitting function can correctly identify the true model within reasonable range.","category":"page"},{"location":"examples/sim_fit/simulate_fit/","page":"Fitting Function","title":"Fitting Function","text":"result_1.model_fit.α","category":"page"},{"location":"examples/sim_fit/simulate_fit/","page":"Fitting Function","title":"Fitting Function","text":"2×5 Array{Float64,2}:\n -0.431755  1.06875  -0.0501667  0.0951105  1.19667\n  0.0       0.0       0.0        0.0        0.0","category":"page"},{"location":"examples/sim_fit/simulate_fit/","page":"Fitting Function","title":"Fitting Function","text":"result_1.model_fit.comp_dist","category":"page"},{"location":"examples/sim_fit/simulate_fit/","page":"Fitting Function","title":"Fitting Function","text":"2×2 Array{AnyExpert{LRMoE.NonNegative,z,d} where d<:(Distribution{Univariat\ne,S} where S<:ValueSupport) where z<:ZeroInflation,2}:\n PoissonExpert{Float64}(6.01676)              …  ZIGammaCountExpert{Float64\n}(0.206196, 29.9564, 0.488854)\n LogNormalExpert{Float64}(4.00105, 0.296734)     InverseGaussianExpert{Floa\nt64}(20.3037, 21.7569)","category":"page"},{"location":"examples/sim_fit/simulate_fit/","page":"Fitting Function","title":"Fitting Function","text":"In practice, it is almost impossible to know the true underlying distribution of data.  Assume the user has conducted some preliminary analysis, and proposes to use the following LRMoE.","category":"page"},{"location":"examples/sim_fit/simulate_fit/","page":"Fitting Function","title":"Fitting Function","text":"# Assume a non-informative guess\nα_guess = fill(0.0, 2, 5)\n# Incorrectly specified component distributions\nmodel_guess = [ZIPoissonExpert(0.50, 10.0) ZIPoissonExpert(0.50, 20.0);\n               BurrExpert(5.0, 2.0, 30.0) GammaExpert(1.0, 10.0)]","category":"page"},{"location":"examples/sim_fit/simulate_fit/","page":"Fitting Function","title":"Fitting Function","text":"We call the fitting function similarly as before.","category":"page"},{"location":"examples/sim_fit/simulate_fit/","page":"Fitting Function","title":"Fitting Function","text":"result_2 = fit_LRMoE(Y_obs, X_obs, α_guess, model_guess, penalty=true)","category":"page"},{"location":"examples/sim_fit/simulate_fit/","page":"Fitting Function","title":"Fitting Function","text":"summary(result_2)","category":"page"},{"location":"examples/sim_fit/simulate_fit/","page":"Fitting Function","title":"Fitting Function","text":"Model: LRMoE\nFitting converged after 29 iterations\nDimension of response: 2\nNumber of components: 2\nLoglik: -74522.97988044818\nLoglik (no penalty): -74491.23826492707\nAIC: 149010.47652985415\nBIC: 149111.19121477133\nFitted α:\n[-0.402329688892696 1.0642517348023806 -0.04993352290476096 0.0955025073281\n0937 1.1787815897308458; 0.0 0.0 0.0 0.0 0.0]\nFitted component distributions:\nAnyExpert{LRMoE.NonNegative,z,d} where d<:(Distribution{Univariate,S} where\n S<:ValueSupport) where z<:ZeroInflation[ZIPoissonExpert{Float64}(0.0032705\n87671859084, 6.1027631872596455) ZIPoissonExpert{Float64}(0.206265076006209\n33, 30.584982151431703); BurrExpert{Float64}(1.3092510512796607, 5.23197932\n44529444, 58.7993745083068) GammaExpert{Float64}(1.6243105423038051, 12.398\n187227236122)]","category":"page"},{"location":"examples/sim_fit/simulate_fit/#Fitted-Results","page":"Fitting Function","title":"Fitted Results","text":"","category":"section"},{"location":"examples/sim_fit/simulate_fit/","page":"Fitting Function","title":"Fitting Function","text":"We can visually examine the fitted results of result_1 and result_2. The following histogram compares dimension 1 of the observed data (green)  with fitted model 1 (blue) and model 2 (red). Since the true model has a slightly heavy tail due to the gamma-count component, model 2 fails to capture this characteristics with only two Poisson components.","category":"page"},{"location":"examples/sim_fit/simulate_fit/","page":"Fitting Function","title":"Fitting Function","text":"(Image: )","category":"page"},{"location":"examples/sim_fit/simulate_fit/","page":"Fitting Function","title":"Fitting Function","text":"The histogram below shows the fitting result for the second dimension (excluding zero inflation). Both models fit the body of data quite well. This is partly because both Burr and Inverse Gaussian distributions are dense (see Fung et al. (2019)).  In other words, they are flexible enough to capture the distribution of response, even under a mis-specified model.","category":"page"},{"location":"examples/sim_fit/simulate_fit/","page":"Fitting Function","title":"Fitting Function","text":"(Image: )","category":"page"},{"location":"examples/sim_fit/simulate_fit/","page":"Fitting Function","title":"Fitting Function","text":"The fitting results can also be demonstrated with the following Q-Q plots. For both dimensions of the response, the mis-specified model 2 gives a slightly worse fit for the tails.","category":"page"},{"location":"examples/sim_fit/simulate_fit/","page":"Fitting Function","title":"Fitting Function","text":"(Image: )","category":"page"},{"location":"examples/sim_fit/simulate_fit/","page":"Fitting Function","title":"Fitting Function","text":"(Image: )","category":"page"},{"location":"init/#Model-Initialization","page":"Model Initialization","title":"Model Initialization","text":"","category":"section"},{"location":"init/","page":"Model Initialization","title":"Model Initialization","text":"cmm_init","category":"page"},{"location":"init/#LRMoE.cmm_init","page":"Model Initialization","title":"LRMoE.cmm_init","text":"cmm_init(Y, X, n_comp, type; exact_Y = false, n_random = 5)\n\nInitialize an LRMoE model using the Clustered Method of Moments (CMM).\n\nArguments\n\nY: A matrix of response.\nX: A matrix of covariates.\nn_comp: Integer. Number of latent classes/components.\ntype: A vector of either continuous, discrete or real, indicating the type of response by dimension.\n\nOptional Arguments\n\nexact_Y: true or false (default), indicating if Y is observed exactly or with censoring and truncation.\nn_random: Integer. Number of randomized initializations. \n\nReturn Values\n\nzero_y: Proportion of zeros in observed Y.\nmean_y_pos: Mean of positive observations in Y.\nvar_y_pos: Variance of positive observations in Y.\nskewness_y_pos: Skewness of positive observations in Y.\nkurtosis_y_pos: Kurtosis of positive observations in Y.\nα_init: Initialization of logit regression coefficients α.\nparams_init: Initializations of expert functions. It is a three-dimensional vector.    For example, params_init[1][2] initializes the 1st dimension of Y using the 2nd latent class,   which is a vector of potential expert functions to choose from.\nll_init: Calculates the loglikelihood of each expert function on the clustered groups of Y.   For example, ll_init[1][2][3] is the loglikelihood of the 1st dimension of Y, calculated based   on the 2nd latent classes and the 3rd initialized expert function in params_init.\nll_best: An initialization chosen from params_init which yields the highest likelihood upon initialization.\nrandom_init: A list of n_random randomized initializations chosen from params_init.\n\n\n\n\n\n","category":"function"},{"location":"examples/sim_data/simulate_data/#Introduction","page":"Data Simulation","title":"Introduction","text":"","category":"section"},{"location":"examples/sim_data/simulate_data/","page":"Data Simulation","title":"Data Simulation","text":"This document contains the data generation process for the dataset accompanying  the LRMoE.jl package (see here). This also serves as an example of using the sim_dataset function  included in the package.","category":"page"},{"location":"examples/sim_data/simulate_data/#Data-Simulation","page":"Data Simulation","title":"Data Simulation","text":"","category":"section"},{"location":"examples/sim_data/simulate_data/#Complete-Data","page":"Data Simulation","title":"Complete Data","text":"","category":"section"},{"location":"examples/sim_data/simulate_data/","page":"Data Simulation","title":"Data Simulation","text":"Suppose there is an auto-insurance company with two lines of business, with a total of 10,000 policies.  The policyholder information includes sex (1 for Male and 0 for Female), driver's age (with range 20 - 80),  car age (with range 0 - 10), and region (1 for urban and 0 for rural).  We assume all covariates are uniformly and independently drawn at random.","category":"page"},{"location":"examples/sim_data/simulate_data/","page":"Data Simulation","title":"Data Simulation","text":"# Random seed for reproducible results\nRandom.seed!(7777)\nsample_size = 10000\n\nintercept = fill(1.0, sample_size)\nsex = rand(Binomial(1, 0.50), sample_size)\naged = rand(Uniform(20, 80), sample_size)\nagec = rand(Uniform(0, 10), sample_size)\nregion = rand(Binomial(1, 0.50), sample_size)\n\nX = DataFrame(intercept = intercept, sex= sex, \n              aged = aged, agec = agec, region = region)","category":"page"},{"location":"examples/sim_data/simulate_data/","page":"Data Simulation","title":"Data Simulation","text":"The first few rows of X are shown below.","category":"page"},{"location":"examples/sim_data/simulate_data/","page":"Data Simulation","title":"Data Simulation","text":"5×5 DataFrame\n Row │ intercept  sex    aged     agec     region\n     │ Float64    Int64  Float64  Float64  Int64\n─────┼────────────────────────────────────────────\n   1 │       1.0      1  56.4367  3.3857        1\n   2 │       1.0      1  29.7025  2.31892       1\n   3 │       1.0      1  33.4796  8.61125       0\n   4 │       1.0      0  38.7478  2.88865       1\n   5 │       1.0      1  47.348   9.01135       0","category":"page"},{"location":"examples/sim_data/simulate_data/","page":"Data Simulation","title":"Data Simulation","text":"For simplicity, we assume there are two latent risk classes: low (L) and high (H).  The characteristics for the high-risk class are male, young age, old car age and urban region.  This is specified by the following matrix of logit regression coefficients,  where the second row represents the reference class.","category":"page"},{"location":"examples/sim_data/simulate_data/","page":"Data Simulation","title":"Data Simulation","text":"α = [-0.5 1.0 -0.05 0.1 1.25;\n      0.0 0.0   0.0 0.0  0.0]","category":"page"},{"location":"examples/sim_data/simulate_data/","page":"Data Simulation","title":"Data Simulation","text":"We consider a two-dimensional response: claim frequency from the first business line,  and claim severity from the second business line.  For demonstration purposes and for simplicity, we don't consider the same business line to avoid the complication  where zero frequency necessarily implies zero severity.  The component distributions and their parameters are specified as follows.","category":"page"},{"location":"examples/sim_data/simulate_data/","page":"Data Simulation","title":"Data Simulation","text":"comp_dist = [PoissonExpert(6.0)         ZIGammaCountExpert(0.20, 30, 0.50);\n             LogNormalExpert(4.0, 0.3)  InverseGaussianExpert(20, 20)]","category":"page"},{"location":"examples/sim_data/simulate_data/","page":"Data Simulation","title":"Data Simulation","text":"The LRMoE.jl package includes a simulator. Given the covariates and parameters defined above,  we can directly simulate a dataset.","category":"page"},{"location":"examples/sim_data/simulate_data/","page":"Data Simulation","title":"Data Simulation","text":"Y_complete = LRMoE.sim_dataset(α, X, comp_dist)","category":"page"},{"location":"examples/sim_data/simulate_data/","page":"Data Simulation","title":"Data Simulation","text":"The simulated values are plotted as follows.  For each dimension of Y, the histogram is relatively well separated as two components.  This is more or less done on purpose to demonstrate that the fitting procedure can identify the true model  when it is known.  In practice, we are usually less concerned of the underlying data generating distribution,  as long as the LRMoE model provides a reasonable fit of data.","category":"page"},{"location":"examples/sim_data/simulate_data/","page":"Data Simulation","title":"Data Simulation","text":"(Image: )","category":"page"},{"location":"examples/sim_data/simulate_data/","page":"Data Simulation","title":"Data Simulation","text":"(Image: )","category":"page"},{"location":"examples/sim_data/simulate_data/#Truncation-and-Censoring","page":"Data Simulation","title":"Truncation and Censoring","text":"","category":"section"},{"location":"examples/sim_data/simulate_data/","page":"Data Simulation","title":"Data Simulation","text":"One distinct feature of LRMoE is dealing with data truncation and censoring,  which is common in insurance contexts.  Consequently, instead of one single number for each dimension d, a tuple (tl_d, yl_d, yu_d, tu_d) is required,   where tl_d/tu_d are the lower/upper bounds of truncation, and yl_d/yu_d are the lower/upper bounds of censoring.","category":"page"},{"location":"examples/sim_data/simulate_data/","page":"Data Simulation","title":"Data Simulation","text":"For illustration purposes, we assume the dataset is subject to the following truncation and censoring.","category":"page"},{"location":"examples/sim_data/simulate_data/","page":"Data Simulation","title":"Data Simulation","text":"Index Y_complete[:,1] Y_complete[:,2]\n1-6000 No truncation  or censoring No truncation  or censoring\n6001-8000 No truncation  or censoring Left Truncated at 5\n8001-10000 No truncation  or censoring Right Censored at 100","category":"page"},{"location":"examples/sim_data/simulate_data/","page":"Data Simulation","title":"Data Simulation","text":"# First block: 1~6000\nX_obs = X[1:6000,:]\n\ntl_1 = fill(0.0, 6000)\nyl_1 = Y_complete[1:6000, 1]\nyu_1 = Y_complete[1:6000, 1]\ntu_1 = fill(Inf, 6000) \n\ntl_2 = fill(0.0, 6000)\nyl_2 = Y_complete[1:6000, 2]\nyu_2 = Y_complete[1:6000, 2]\ntu_2 = fill(Inf, 6000) \n\n# Second block: 6001~8000\nkeep_idx = Y_complete[6001:8000,2] .>=  5\nkeep_length = sum(keep_idx) # 1837 out of 2000\n\nappend!(X_obs, X[6001:8000,:][keep_idx,:])\n\nappend!(tl_1, fill(0.0, keep_length))\nappend!(yl_1, Y_complete[6001:8000, 1][keep_idx])\nappend!(yu_1, Y_complete[6001:8000, 1][keep_idx])\nappend!(tu_1, fill(Inf, keep_length))\n\ny_temp = Y_complete[6001:8000, 2][keep_idx]\nappend!(tl_2, fill(5.0, keep_length))\nappend!(yl_2, Y_complete[6001:8000, 2][keep_idx])\nappend!(yu_2, Y_complete[6001:8000, 2][keep_idx])\nappend!(tu_2, fill(Inf, keep_length))\n\n# Third block: 8001~10000\nappend!(X_obs, X[8001:10000,:])\n\nappend!(tl_1, fill(0.0, 2000))\nappend!(yl_1, Y_complete[8001:10000, 1])\nappend!(yu_1, Y_complete[8001:10000, 1])\nappend!(tu_1, fill(Inf, 2000))\n\ny_temp = Y_complete[8001:10000, 2]\ncensor_idx = y_temp .>= 100.0 # 21 out of 2000\nyl_temp = copy(y_temp)\nyl_temp[censor_idx] .= 100\nyu_temp = copy(y_temp)\nyu_temp[censor_idx] .= Inf\nappend!(tl_2, fill(0.0, 2000))\nappend!(yl_2, yl_temp)\nappend!(yu_2, yu_temp)\nappend!(tu_2, fill(Inf, 2000))\n\n# Put things together\nY_obs = DataFrame(tl_1 = tl_1, yl_1 = yl_1, yu_1 = yu_1, tu_1 = tu_1,\n                  tl_2 = tl_2, yl_2 = yl_2, yu_2 = yu_2, tu_2 = tu_2)","category":"page"},{"location":"examples/sim_data/simulate_data/","page":"Data Simulation","title":"Data Simulation","text":"As a result of truncating Y_complete[:,2], 163 rows are discarded,  leaving 9837 observations available for model fitting. Sample data points are show below.","category":"page"},{"location":"examples/sim_data/simulate_data/","page":"Data Simulation","title":"Data Simulation","text":"3×4 DataFrame\n Row │ tl_1     yl_1     yu_1     tu_1\n     │ Float64  Float64  Float64  Float64\n─────┼────────────────────────────────────\n   1 │     0.0      6.0      6.0     Inf\n   2 │     0.0      8.0      8.0     Inf\n   3 │     0.0      7.0      7.0     Inf","category":"page"},{"location":"examples/sim_data/simulate_data/","page":"Data Simulation","title":"Data Simulation","text":"3×4 DataFrame\n Row │ tl_2     yl_2      yu_2      tu_2\n     │ Float64  Float64   Float64   Float64\n─────┼──────────────────────────────────────\n   1 │     0.0   89.0332   89.0332     Inf\n   2 │     5.0   37.4133   37.4133     Inf\n   3 │     0.0  100.0     Inf          Inf","category":"page"},{"location":"examples/sim_data/simulate_data/","page":"Data Simulation","title":"Data Simulation","text":"We will export both the complete and incomplete datasets to the LRMoE.jl package.","category":"page"},{"location":"examples/sim_data/simulate_data/","page":"Data Simulation","title":"Data Simulation","text":"@save \"X_complete.jld2\" X\n@save \"Y_complete.jld2\" Y_complete\n@save \"X_obs.jld2\" X_obs\n@save \"Y_obs.jld2\" Y_obs","category":"page"},{"location":"framework/#Modelling-Framework","page":"Modelling Framework","title":"Modelling Framework","text":"","category":"section"},{"location":"framework/","page":"Modelling Framework","title":"Modelling Framework","text":"The LRMoE model is formulated as follows. Let (mathbfx_i mathbfy_i) i = 1 2 dots n denote a set of observations, where mathbfx_i denotes the covariates and mathbfy_i the response(s).","category":"page"},{"location":"framework/","page":"Modelling Framework","title":"Modelling Framework","text":"Given mathbfx_i, the i-th observation is classified into one of g latent classes by the so-called logit gating function. The probability of belonging to the j-th latent class is given by","category":"page"},{"location":"framework/","page":"Modelling Framework","title":"Modelling Framework","text":"pi_j(mathbfx_i mathbfalpha) = fracexp (mathbfalpha_j^T mathbfx_i)sum_j=1^g exp (mathbfalpha_j^T mathbfx_i) quad j = 1 2 dots g-1","category":"page"},{"location":"framework/","page":"Modelling Framework","title":"Modelling Framework","text":"For model identifiability reasons, we assume mathbfalpha_g = mathbf0 which corresponds to the reference class.","category":"page"},{"location":"framework/","page":"Modelling Framework","title":"Modelling Framework","text":"Conditional on the latent class j, the distribution of the response mathbfy_i is given by an expert function with density","category":"page"},{"location":"framework/","page":"Modelling Framework","title":"Modelling Framework","text":"f_j(mathbfy_i mathbfpsi_j) = prod_d=1^D f_jd(mathbfy_id mathbfpsi_jd)","category":"page"},{"location":"framework/","page":"Modelling Framework","title":"Modelling Framework","text":"where we assume conditional independence of dimensions 1 2 dots D of mathbfy_i, if it is a vector of responses.","category":"page"},{"location":"framework/","page":"Modelling Framework","title":"Modelling Framework","text":"The likelihood function is therefore","category":"page"},{"location":"framework/","page":"Modelling Framework","title":"Modelling Framework","text":"L(mathbfalpha mathbfpsi mathbfx mathbfy) = prod_i=1^n left sum_j=1^g pi_j(mathbfx_i mathbfalpha) f_j(mathbfy_i mathbfpsi_j) right","category":"page"},{"location":"framework/","page":"Modelling Framework","title":"Modelling Framework","text":"Notice that the parameters mathbfpsi_j do not involve regression on the covariates mathbfx_i, hence the model is termed as reduced. For an introduction to the general mixture-of-experts models, see e.g. here.","category":"page"},{"location":"framework/","page":"Modelling Framework","title":"Modelling Framework","text":"Fung et al. (2019) have shown that such simplification of model structure will not reduce its flexibility, and will significantly reduce the computation efforts in model inference. The parameters to estimate are the regression coefficients mathbfalpha_j and parameters of the expert functions mathbfpsi_j, which is implemented by the standard Expectation-Conditional-Maximization algorithm (details omitted).","category":"page"},{"location":"experts/#Expert-Functions","page":"Expert Functions","title":"Expert Functions","text":"","category":"section"},{"location":"experts/","page":"Expert Functions","title":"Expert Functions","text":"The LRMoE.jl package supports a collection of distributions commonly used for modelling insurance claim frequency and severity.","category":"page"},{"location":"experts/#Discrete-Distributions-(Frequency-Modelling)","page":"Expert Functions","title":"Discrete Distributions (Frequency Modelling)","text":"","category":"section"},{"location":"experts/","page":"Expert Functions","title":"Expert Functions","text":"BinomialExpert\nNegativeBinomialExpert\nPoissonExpert\nGammaCountExpert","category":"page"},{"location":"experts/#LRMoE.BinomialExpert","page":"Expert Functions","title":"LRMoE.BinomialExpert","text":"BinomialExpert(n, p)\n\nPMF:\n\nP(X = k) = n choose kp^k(1-p)^n-k  quad text for  k = 012 ldots n\n\nSee also: Binomial Distribution (Wikipedia) \n\n\n\n\n\n","category":"type"},{"location":"experts/#LRMoE.NegativeBinomialExpert","page":"Expert Functions","title":"LRMoE.NegativeBinomialExpert","text":"NegativeBinomialExpert(n, p)\n\nPMF:\n\nP(X = k) = fracGamma(k+r)k Gamma(r) p^r (1 - p)^k quad textfor  k = 012ldots\n\nSee also: Negative Binomial Distribution (Wolfram) \n\n\n\n\n\n","category":"type"},{"location":"experts/#LRMoE.PoissonExpert","page":"Expert Functions","title":"LRMoE.PoissonExpert","text":"PoissonExpert(λ)\n\nPMF:\n\nP(X = k) = fraclambda^kk e^-lambda quad text for  k = 012ldots\n\nSee also: Poisson Distribution (Wikipedia) \n\n\n\n\n\n","category":"type"},{"location":"experts/#LRMoE.GammaCountExpert","page":"Expert Functions","title":"LRMoE.GammaCountExpert","text":"GammaCountExpert(m, s)\n\nPMF:\n\nP(X = k) = G(m k s T) - G(m (k+1) s T) quad text for  k = 012 ldots n\n\nwith\n\nG(m k s T) = frac1Gamma(mk)  int^sT_0 u^mk - 1 e^-u du\n\nSee also: Gamma Count Distribution (Arxiv) \n\n\n\n\n\n","category":"type"},{"location":"experts/#Continuous-Distributions-(Severity-Modelling)","page":"Expert Functions","title":"Continuous Distributions (Severity Modelling)","text":"","category":"section"},{"location":"experts/","page":"Expert Functions","title":"Expert Functions","text":"BurrExpert\nGammaExpert\nInverseGaussianExpert\nLogNormalExpert\nWeibullExpert","category":"page"},{"location":"experts/#LRMoE.BurrExpert","page":"Expert Functions","title":"LRMoE.BurrExpert","text":"BurrExpert(k, c, λ)\n\nPDF:\n\nf(x k c lambda) = frackclambda left( fracxlambda right)^c-1 left( 1+ left( fracxlambda right)^c right)^-k-1\nquad x geq 0\n\nSee also: Burr Distribution (Mathworks, implemented in this package),     Burr Distribution (Wikipedia, with λ = 1)\n\n\n\n\n\n","category":"type"},{"location":"experts/#LRMoE.GammaExpert","page":"Expert Functions","title":"LRMoE.GammaExpert","text":"GammaExpert(k, θ)\n\nPDF:\n\nf(x k theta) = fracx^k-1 e^-xthetaGamma(k) theta^k\nquad x  0\n\nSee also: Gamma Distribution (Wikipedia), shape-scale parameterization \n\n\n\n\n\n","category":"type"},{"location":"experts/#LRMoE.InverseGaussianExpert","page":"Expert Functions","title":"LRMoE.InverseGaussianExpert","text":"InverseGaussianExpert(μ, λ)\n\nPDF:\n\nf(x mu lambda) = sqrtfraclambda2pi x^3\nexpleft(frac-lambda(x-mu)^22mu^2xright) \nquad x  0\n\nSee also: Inverse Gaussian Distribution (Wikipedia) \n\n\n\n\n\n","category":"type"},{"location":"experts/#LRMoE.LogNormalExpert","page":"Expert Functions","title":"LRMoE.LogNormalExpert","text":"LogNormalExpert(μ, σ)\n\nPDF:\n\nf(x mu sigma) = frac1x sqrt2 pi sigma^2\nexp left( - frac(log(x) - mu)^22 sigma^2 right)\nquad x  0\n\nSee also: Lognormal Distribution (Wikipedia)\n\n\n\n\n\n","category":"type"},{"location":"experts/#LRMoE.WeibullExpert","page":"Expert Functions","title":"LRMoE.WeibullExpert","text":"WeibullExpert(k, θ)\n\nPDF:\n\nf(x k theta) = fracktheta left( fracxtheta right)^k-1 e^-(xtheta)^k\nquad x geq 0\n\nSee also: Weibull Distribution (Wikipedia) \n\n\n\n\n\n","category":"type"},{"location":"experts/#Zero-Inflation","page":"Expert Functions","title":"Zero Inflation","text":"","category":"section"},{"location":"experts/","page":"Expert Functions","title":"Expert Functions","text":"Zero inflation is supported for all discrete and continuous experts. They can be constructed by adding ZI in front of an expert function, with an additional parameter p (or p0 if the expert already uses p, e.g. binomial) for modelling a probability mass at zero. Zero-inflated experts are used in the same way as their non-zero-inflated counterpart. A complete list of  zero-inflated expert functions is given below.","category":"page"},{"location":"experts/","page":"Expert Functions","title":"Expert Functions","text":"ZIBinomialExpert(p0, n, p)\nZINegativeBinomialExpert(p0, n, p)\nZIPoissonExpert(p, λ)\nZIGammaCountExpert(p, m, s)","category":"page"},{"location":"experts/","page":"Expert Functions","title":"Expert Functions","text":"ZIBurrExpert(p, k, c, λ)\nZIGammaExpert(p, k, θ)\nZIInverseGaussianExpert(p, μ, λ)\nZILogNormalExpert(p, μ, σ)\nZIWeibullExpert(p, k, θ)","category":"page"},{"location":"experts/#Adding-Customized-Expert-Functions","page":"Expert Functions","title":"Adding Customized Expert Functions","text":"","category":"section"},{"location":"experts/","page":"Expert Functions","title":"Expert Functions","text":"See here.","category":"page"},{"location":"customize/#customize_experts","page":"Adding Customized Expert Functions","title":"Adding Customized Expert Functions","text":"","category":"section"},{"location":"customize/","page":"Adding Customized Expert Functions","title":"Adding Customized Expert Functions","text":"In addition to the expert functions included in the package, users can also write their own expert functions specific to a particular modelling problem (not confined within actuarial contexts).","category":"page"},{"location":"customize/#Type-Hierarchy","page":"Adding Customized Expert Functions","title":"Type Hierarchy","text":"","category":"section"},{"location":"customize/","page":"Adding Customized Expert Functions","title":"Adding Customized Expert Functions","text":"Expert functions are implemented as subtypes of the AnyExpert type in this package. A good number of expert functions are simply wrappers around the UnivariateDistribution type in Distributions.jl (details here), and functions such as pdf and cdf are also directly using those in Distributions.jl.","category":"page"},{"location":"customize/","page":"Adding Customized Expert Functions","title":"Adding Customized Expert Functions","text":"Expert functions can be defined either on the real line, or only on nonnegative values (as is usually the case for actuarial loss modelling).","category":"page"},{"location":"customize/","page":"Adding Customized Expert Functions","title":"Adding Customized Expert Functions","text":"# Abstract type: support of expert function\nabstract type ExpertSupport end\nstruct RealValued <: ExpertSupport end\nstruct NonNegative <: ExpertSupport end","category":"page"},{"location":"customize/","page":"Adding Customized Expert Functions","title":"Adding Customized Expert Functions","text":"Considering zero inflation is prominant in many actuarial applications, expert functions can be either zero-inflated or not, provided that they are supported only on nonnegative values.","category":"page"},{"location":"customize/","page":"Adding Customized Expert Functions","title":"Adding Customized Expert Functions","text":"# Abstract type: whether the expert is zero-inflated\nabstract type ZeroInflation end\nstruct ZI <: ZeroInflation end\nstruct NonZI <: ZeroInflation end","category":"page"},{"location":"customize/","page":"Adding Customized Expert Functions","title":"Adding Customized Expert Functions","text":"Each expert function is a univariate distribution (see here for UnivariateDistribution in Distributions.jl), with appropriate indication of support and zero inflation. ","category":"page"},{"location":"customize/","page":"Adding Customized Expert Functions","title":"Adding Customized Expert Functions","text":"# Abstract type: AnyExpert\nabstract type AnyExpert{s<:ExpertSupport, z<:ZeroInflation, d<:UnivariateDistribution} end\n# Discrete or Continuous\nconst DiscreteExpert{s<:ExpertSupport, z<:ZeroInflation} = \n                AnyExpert{s, z, DiscreteUnivariateDistribution}\nconst ContinuousExpert{s<:ExpertSupport, z<:ZeroInflation} = \n                AnyExpert{s, z, ContinuousUnivariateDistribution}\n# Real-valued expert distributions\nconst RealDiscreteExpert = DiscreteExpert{RealValued, NonZI}\nconst RealContinuousExpert = ContinuousExpert{RealValued, NonZI}\n# Nonnegative-valued expert distributions\nconst NonNegDiscreteExpert{z<:ZeroInflation} = DiscreteExpert{NonNegative, z}\nconst NonNegContinuousExpert{z<:ZeroInflation} = ContinuousExpert{NonNegative, z}\n# Zero-inflated\nconst ZIDiscreteExpert = NonNegDiscreteExpert{ZI}\nconst ZIContinuousExpert = NonNegContinuousExpert{ZI}\n# Non zero-inflated\nconst NonZIDiscreteExpert = NonNegDiscreteExpert{NonZI}\nconst NonZIContinuousExpert = NonNegContinuousExpert{NonZI}","category":"page"},{"location":"customize/#Example:-Gamma-Expert","page":"Adding Customized Expert Functions","title":"Example: Gamma Expert","text":"","category":"section"},{"location":"customize/","page":"Adding Customized Expert Functions","title":"Adding Customized Expert Functions","text":"As an example, we will use the Gamma expert to demonstrate how to write a customized expert function for any continuous distribution. For discrete distributions, the Poisson distribution is a good example, but we will omit the details here. In this illustrative example, we will go through the source code of Gamma Expert (available here) to see what is needed to add a customized expert function.","category":"page"},{"location":"customize/","page":"Adding Customized Expert Functions","title":"Adding Customized Expert Functions","text":"Before starting, we create a new source code file gamma.jl for Gamma expert, and  put it in the corresponding folder, i.e. src/experts/continuous.","category":"page"},{"location":"customize/#Defining-a-struct","page":"Adding Customized Expert Functions","title":"Defining a struct","text":"","category":"section"},{"location":"customize/","page":"Adding Customized Expert Functions","title":"Adding Customized Expert Functions","text":"The first step is to define the Gamma expert function and some basic and common functions shared by all experts. This corresponds to the first block of the source code. The details are quite similar to  adding a customized distribution to Distributions.jl, including defining the new GammaExpert as a sub-type of NonZIContinuousExpert,  some constructors and conversions of parameters.","category":"page"},{"location":"customize/","page":"Adding Customized Expert Functions","title":"Adding Customized Expert Functions","text":"struct GammaExpert{T<:Real} <: NonZIContinuousExpert\n    k::T\n    θ::T\n    GammaExpert{T}(k::T, θ::T) where {T<:Real} = new{T}(k, θ)\nend\n\nfunction GammaExpert(k::T, θ::T; check_args=true) where {T <: Real}\n    check_args && @check_args(GammaExpert, k >= zero(k) && θ > zero(θ))\n    return GammaExpert{T}(k, θ)\nend\n\n## Outer constructors\nGammaExpert(k::Real, θ::Real) = GammaExpert(promote(k, θ)...)\nGammaExpert(k::Integer, θ::Integer) = GammaExpert(float(k), float(θ))\nGammaExpert() = GammaExpert(1.0, 1.0)\n\n## Conversion\nfunction convert(::Type{GammaExpert{T}}, k::S, θ::S) where {T <: Real, S <: Real}\n    GammaExpert(T(k), T(θ))\nend\nfunction convert(::Type{GammaExpert{T}}, d::GammaExpert{S}) where {T <: Real, S <: Real}\n    GammaExpert(T(d.k), T(d.θ), check_args=false)\nend\ncopy(d::GammaExpert) = GammaExpert(d.k, d.θ, check_args=false)","category":"page"},{"location":"customize/#Exporting-the-expert-function","page":"Adding Customized Expert Functions","title":"Exporting the expert function","text":"","category":"section"},{"location":"customize/","page":"Adding Customized Expert Functions","title":"Adding Customized Expert Functions","text":"This step should technically be at the very end, but we introduce it here to facilitate testing during development. In order for the expert function to be accessible to the user, it should be exported by modifying the files src/experts/expert.jl and src/LRMoE.jl: In the former, gamma is added to contintous_experts so that the source file src/experts/continuous/gamma.jl is included; In the latter, GammaExpert is exported so that the gamma expert function is accessible outside of the package.","category":"page"},{"location":"customize/#Basic-and-additional-functions","page":"Adding Customized Expert Functions","title":"Basic and additional functions","text":"","category":"section"},{"location":"customize/","page":"Adding Customized Expert Functions","title":"Adding Customized Expert Functions","text":"For all expert functions, there are a number of basic functions absolutely needed for using the package. In addition, some functions may be omitted (e.g. calculating limited expected value) if they are not relevant to the modeling problem at hand.","category":"page"},{"location":"customize/","page":"Adding Customized Expert Functions","title":"Adding Customized Expert Functions","text":"Basic probability functions: pdf, logpdf, cdf and logcdf. These are used for calculating the loglikelihood of the model. Notice that for logpdf etc., we have directly used the corresponding functions in Distributions.jl since the Gamma distribution is already implemented there. If this is not the case, the user can also add a new distribution type following the guide in Distributions.jl, and add the source code to the folder src/experts/add_dist.","category":"page"},{"location":"customize/","page":"Adding Customized Expert Functions","title":"Adding Customized Expert Functions","text":"## Loglikelihood of Expert\nlogpdf(d::GammaExpert, x...) = (d.k < 1 && x... <= 0.0) ? -Inf : Distributions.logpdf.(Distributions.Gamma(d.k, d.θ), x...)\npdf(d::GammaExpert, x...) = (d.k < 1 && x... <= 0.0) ? 0.0 : Distributions.pdf.(Distributions.Gamma(d.k, d.θ), x...)\nlogcdf(d::GammaExpert, x...) = (d.k < 1 && x... <= 0.0) ? -Inf : Distributions.logcdf.(Distributions.Gamma(d.k, d.θ), x...)\ncdf(d::GammaExpert, x...) = (d.k < 1 && x... <= 0.0) ? 0.0 : Distributions.cdf.(Distributions.Gamma(d.k, d.θ), x...)","category":"page"},{"location":"customize/","page":"Adding Customized Expert Functions","title":"Adding Customized Expert Functions","text":"Parameters and initialization: The following functions are necessary for calling the functions to initialize parameters (e.g. cmm_init_params).","category":"page"},{"location":"customize/","page":"Adding Customized Expert Functions","title":"Adding Customized Expert Functions","text":"In the following params_init function, we assume a vector of observations y, and match the first two moments to solve for the parameters of a gamma distribution. Notice that the function should return an expert function, not the parameter values. Also, an empty expert should also be added to the corresponding list in src/paramsinit.jl. In this case, GammaExpert() is added to _default_expert_continuous.","category":"page"},{"location":"customize/","page":"Adding Customized Expert Functions","title":"Adding Customized Expert Functions","text":"The function ks_distance is used to select an initialization of expert which has the lowest test statistics for the Kolmogorov-Smirnov test, in other words, the K-S distance is minimized. The ks_distance simply calculates the test statistics given a vector of observations y and an expert function GammaExpert (i.e. to see if the observations y come from a Gamma distribution).","category":"page"},{"location":"customize/","page":"Adding Customized Expert Functions","title":"Adding Customized Expert Functions","text":"## Parameters\nparams(d::GammaExpert) = (d.k, d.θ)\nfunction params_init(y, d::GammaExpert)\n    pos_idx = (y .> 0.0)\n    μ, σ2 = mean(y[pos_idx]), var(y[pos_idx])\n    θ_init = σ2/μ\n    k_init = μ/θ_init\n    if isnan(θ_init) || isnan(k_init)\n        return GammaExpert()\n    else\n        return GammaExpert(k_init, θ_init)\n    end\nend\n\n## KS stats for parameter initialization\nfunction ks_distance(y, d::GammaExpert)\n    p_zero = sum(y .== 0.0) / sum(y .>= 0.0)\n    return max(abs(p_zero-0.0), (1-0.0)*HypothesisTests.ksstats(y[y .> 0.0], Distributions.Gamma(d.k, d.θ))[2])\nend","category":"page"},{"location":"customize/","page":"Adding Customized Expert Functions","title":"Adding Customized Expert Functions","text":"Simulation: A simulator is also needed, which simulates a vector of length sample_size from the expert function.","category":"page"},{"location":"customize/","page":"Adding Customized Expert Functions","title":"Adding Customized Expert Functions","text":"## Simululation\nsim_expert(d::GammaExpert, sample_size) = Distributions.rand(Distributions.Gamma(d.k, d.θ), sample_size)","category":"page"},{"location":"customize/","page":"Adding Customized Expert Functions","title":"Adding Customized Expert Functions","text":"Penalty on parameters: This is also required. When fitting mixture models, the EM algorithm may converge to a spurious model with extremely large or small parameter values, which is undesirable for a number of reasons (e.g. giving infinite likelihood, or straight up a NaN error). Hence, a penalty is imposed for these extreme cases. In implementation, we essentially assume the parameters have a prior distribution described by some hyperparameters. Consequently, the EM step is essentially maximizing a posterior loglikelihood.","category":"page"},{"location":"customize/","page":"Adding Customized Expert Functions","title":"Adding Customized Expert Functions","text":"As a rule of thumb, we assume a Gamma prior for positive parameters and a Normal prior for real parameters. For example, the penalty terms for Gamma experts are coded as follows. ","category":"page"},{"location":"customize/","page":"Adding Customized Expert Functions","title":"Adding Customized Expert Functions","text":"## penalty\npenalty_init(d::GammaExpert) = [2.0 10.0 2.0 10.0]\nno_penalty_init(d::GammaExpert) = [1.0 Inf 1.0 Inf]\npenalize(d::GammaExpert, p) = (p[1]-1)*log(d.k) - d.k/p[2] + (p[3]-1)*log(d.θ) - d.θ/p[4]","category":"page"},{"location":"customize/","page":"Adding Customized Expert Functions","title":"Adding Customized Expert Functions","text":"In the function penalize, the hyperparameters are given as a vector p. We assume the shape parameter k of the Gamma expert follows a Gamma prior distribution with shape p[1] and scale p[2]. Analogously, the scale parameter θ of the Gamma expert follows a Gamma prior distribution with shape p[3] and scale p[4]. The penalize function calculates the prior logpdf of the parameters, excluding the constant terms since they are irrelevant to the EM algorithm.","category":"page"},{"location":"customize/","page":"Adding Customized Expert Functions","title":"Adding Customized Expert Functions","text":"The functions penalty_init initializes some default hyperparameters, if they are not given by the user. Similarly, no_penalty_init speficies hyperparameters which poses no penalty, as plugging ion p = [1.0 Inf 1.0 Inf] into the penalize function yields zero. Still, it is recommended to always use some penalty in application to avoid the issue of spurious models mentioned above.","category":"page"},{"location":"customize/","page":"Adding Customized Expert Functions","title":"Adding Customized Expert Functions","text":"Note that the penalty term should be subtracted from the loglikelihood when implementing the M-step of the EM algorithm (see below).","category":"page"},{"location":"customize/","page":"Adding Customized Expert Functions","title":"Adding Customized Expert Functions","text":"Miscellaneous functions: There are a number of miscellaneous functions implemented for the expert function as shown below. They are mainly used in  predictive functions such as predict_mean_prior. It is recommended to code them as well when adding a new expert function, but (some or all of) these functions can be optional if the user only wants to fit an LRMoE model.","category":"page"},{"location":"customize/","page":"Adding Customized Expert Functions","title":"Adding Customized Expert Functions","text":"## statistics\nmean(d::GammaExpert) = mean(Distributions.Gamma(d.k, d.θ))\nvar(d::GammaExpert) = var(Distributions.Gamma(d.k, d.θ))\nquantile(d::GammaExpert, p) = quantile(Distributions.Gamma(d.k, d.θ), p)\nlev(d::GammaExpert, u) = d.θ*d.k*gamma_inc(float(d.k+1), u/d.θ, 0)[1] + u*(1-gamma_inc(float(d.k), u/d.θ,0)[1])\nexcess(d::GammaExpert, u) = mean(d) - lev(d, u)","category":"page"},{"location":"customize/#M-Step:-exact-observation","page":"Adding Customized Expert Functions","title":"M-Step: exact observation","text":"","category":"section"},{"location":"customize/","page":"Adding Customized Expert Functions","title":"Adding Customized Expert Functions","text":"The next step is to implement the M-step of the EM algorithm, which is given in Section 3.2 of Fung et al. (2019). Notice that the cited paper considers the issue of data truncation and censoring, but as a first step, we will just assume all data are observed exactly. Data truncation and censoring are dealt with afterwards.","category":"page"},{"location":"customize/","page":"Adding Customized Expert Functions","title":"Adding Customized Expert Functions","text":"The M-step with exact observation is carried out by the function EM_M_expert_exact in the source code. Note that the function name and arguments should not be altered, since it is referenced in the main fitting function of the package.","category":"page"},{"location":"customize/","page":"Adding Customized Expert Functions","title":"Adding Customized Expert Functions","text":"In short, the goal is to maximize the objective function  z_e_obs * LL, where LL is the loglikelihood of the expert d when observing a vector ye. If the function argument penalty is true, then a penalty term given by hyperparameters pen_params_jk (see also above) is subtracted from the objective function. The function argument expert_ll_pos is a legacy and irrelevant to the M-step when observations ye are exact.","category":"page"},{"location":"customize/","page":"Adding Customized Expert Functions","title":"Adding Customized Expert Functions","text":"For Gamma expert, we are maximizing with respect to k and lambda (without penalty) the objective function z_e_obs multiplied by","category":"page"},{"location":"customize/","page":"Adding Customized Expert Functions","title":"Adding Customized Expert Functions","text":"LL = sum_i = 1^n (k-1)log(y_i) - y_ik - log(Gamma(k)) - klog(lambda).","category":"page"},{"location":"customize/","page":"Adding Customized Expert Functions","title":"Adding Customized Expert Functions","text":"The optimization is done by calling minimizer in Optim.jl, which is ommited in this document. Penalty can also be added in the objective function if the function argument penalty is set to true.","category":"page"},{"location":"customize/","page":"Adding Customized Expert Functions","title":"Adding Customized Expert Functions","text":"Finally, the EM_M_expert_exact returns a Gamma expert object containing the updated parameters, thus completing the M-step.","category":"page"},{"location":"customize/#M-Step:-censored-and-truncated-observation","page":"Adding Customized Expert Functions","title":"M-Step: censored and truncated observation","text":"","category":"section"},{"location":"customize/","page":"Adding Customized Expert Functions","title":"Adding Customized Expert Functions","text":"One important feature of this package is to deal with censored and truncated data, which is common both in and outside actuarial contexts. In this case, the loglikelihood is incomplete, in the sense that y_i above is not known exactly, leading to an additional E-step before the M-step.","category":"page"},{"location":"customize/","page":"Adding Customized Expert Functions","title":"Adding Customized Expert Functions","text":"In particular, the M-step with data censoring and truncation is done by the  function EM_M_step, which takes a few more arguments compared with  EM_M_expert_exact. Again, the function name and arguments should not be altered.","category":"page"},{"location":"customize/","page":"Adding Customized Expert Functions","title":"Adding Customized Expert Functions","text":"Recall that we assume the obsercations are truncated between tl and tu, as well as censored between yl and yu. These lower and upper bounds are needed for the M-step.","category":"page"},{"location":"customize/","page":"Adding Customized Expert Functions","title":"Adding Customized Expert Functions","text":"Censored data points are in the observed dataset. For all the censored observation y, we don't know their exact values, but only know that they are between  yl and yu. Hence, for those observations, we should take the expected value of the loglikelihood, further normalizing them by the probability of falling within this interval (which is equal to exp.(-expert_ll_pos)).","category":"page"},{"location":"customize/","page":"Adding Customized Expert Functions","title":"Adding Customized Expert Functions","text":"For the Gamma expert, we refer to the equation of LL above: the uncertain terms are log(y_i) and y_i, so we should compute their conditional expectation, given that the exact observation is between yl and yu. This corresponds to some numerical integration procedures in the source code. Note that the conditional expectation should be computed with respect to the probability measure implied by the old (i.e. not yet updated) parameters.","category":"page"},{"location":"customize/","page":"Adding Customized Expert Functions","title":"Adding Customized Expert Functions","text":"A similar remark can be made about truncated observations, which are not present in the dataset due to truncation. Those are either smaller than the lower bound of truncation tl, or larger than the upper bound of truncation tu. In addition, the function argument k_e is equal to the expected number of lost observations due to truncation, which should also be multiplied to the conditional expectation of loglikelihood.","category":"page"},{"location":"customize/","page":"Adding Customized Expert Functions","title":"Adding Customized Expert Functions","text":"To be more specific, we also numerically integrate log(y_i) and y_i in LL, but from 0 to tl and from tu to Inf. Then, we normalize it by the probability exp.(-expert_tn_bar_pos) to obtain the conditional expectation. Finally, the loglikelihood is further multiplied by k_e to account for all unobserved data points due to truncation.","category":"page"},{"location":"customize/","page":"Adding Customized Expert Functions","title":"Adding Customized Expert Functions","text":"Finally, the loglikelihood of truncated observations is added to the objective function for optimization.","category":"page"},{"location":"customize/#Notes-and-tips","page":"Adding Customized Expert Functions","title":"Notes and tips","text":"","category":"section"},{"location":"customize/","page":"Adding Customized Expert Functions","title":"Adding Customized Expert Functions","text":"There are quite a few things to note when adding a customized expert function.","category":"page"},{"location":"customize/","page":"Adding Customized Expert Functions","title":"Adding Customized Expert Functions","text":"Exact observations: If the problem at hand only concerns exact observations, then the user can write the EM_M_exact function only.\nSpeeding up numerical integration: In EM_M_step, numerical integration for certain expert functions can take a long time. In the gamma.jl example, the author has first looked up for unique lower and upper bounds, and only integrate using those pairs. Then, the numerical integration is mapped to the original dataset. Users are advised to also take this approach, which can be done by conveniently copying and modifying the source code of gamma.jl.\nOptimization constraits: Some expert functions pose constrants on the parameters, e.g. the parameters of Gamma experts should be positive. However, constrained optimization can be computationally slow. In gamma.jl, we have used a log transformation, so that the optimization procedure Optim.optimize is unconstrained. Also, specifying a small search interval speeds things up.\nZero inflation: For zero-inflated expert functions, the M-step should only take in positive observations for continuous experts, but all non-negative observations for discrete experts. See gamma.jl and poisson.jl for a comparison.","category":"page"},{"location":"customize/","page":"Adding Customized Expert Functions","title":"Adding Customized Expert Functions","text":"For further questions and tips when customizing expert functions, please contact the author on github.","category":"page"},{"location":"fit/#Fitting-Functions","page":"Fitting Function","title":"Fitting Functions","text":"","category":"section"},{"location":"fit/","page":"Fitting Function","title":"Fitting Function","text":"fit_LRMoE\nsummary","category":"page"},{"location":"fit/#LRMoE.fit_LRMoE","page":"Fitting Function","title":"LRMoE.fit_LRMoE","text":"fit_LRMoE(Y, X, α_init, model; ...)\n\nFit an LRMoE model.\n\nArguments\n\nY: A matrix of response.\nX: A matrix of covariates.\nα: A matrix of logit regression coefficients.\nmodel: A matrix specifying the expert functions.\n\nOptional Arguments\n\nexact_Y: true or false (default), indicating if Y is observed exactly or with censoring and truncation.\npenalty: true (default) or false, indicating whether penalty is imposed on the magnitude of parameters.\npen_α: a numeric penalty on the magnitude of logit regression coefficients. Default is 1.0.\npen_params: an array of penalty term on the magnitude of parameters of component distributions/expert functions.\nϵ: Stopping criterion on loglikelihood (stop when the increment is less than ϵ). Default is 0.001.\nα_iter_max: Maximum number of iterations when updating α. Default is 5.\necm_iter_max: Maximum number of iterations of the ECM algorithm. Default is 200.\ngrad_jump: IN DEVELOPMENT\ngrad_seq: IN DEVELOPMENT\nprint_steps: true (default) or false, indicating whether intermediate updates of parameters should be logged.\n\nReturn Values\n\nmodel_result.α_fit: Fitted values of logit regression coefficients α.\nmodel_result.comp_dist: Fitted parameters of expert functions.\nconverge: true or false, indicating whether the fitting procedure has converged.\niter: Number of iterations passed in the fitting function.\nll: Loglikelihood of the fitted model (with penalty on the magnitude of parameters).\nll_np: Loglikelihood of the fitted model (without penalty on the magnitude of parameters).\nAIC: Akaike Information Criterion (AIC) of the fitted model.\nBIC: Bayesian Information Criterion (BIC) of the fitted model.\n\n\n\n\n\n","category":"function"},{"location":"fit/#Base.summary","page":"Fitting Function","title":"Base.summary","text":"summary(obj)\n\nSummarizes a fitted LRMoE model.\n\nArguments\n\nobj: An object returned by fit_LRMoE function.\n\nReturn Values\n\nPrints out a summary of the fitted LRMoE model on screen.\n\n\n\n\n\n","category":"function"},{"location":"data_format/#Data-Formatting","page":"Data Formatting","title":"Data Formatting","text":"","category":"section"},{"location":"data_format/","page":"Data Formatting","title":"Data Formatting","text":"There are a few data formatting issues to note when using the LRMoE package, which are summarized below. Throughout this page, we assume there are N = 100 insurance policyholders,  who have two coverages y_1 and y_2 (dimension of response D = 2). Each policyholder has 5 covariates (number of covariates P = 5).","category":"page"},{"location":"data_format/","page":"Data Formatting","title":"Data Formatting","text":"Covariate X: The dimension of X should be 100 by 5 (= N * P), which is relatively straightforward.   If there are factor covariates (e.g. indicators for urban and rural region), the intercept term should    be manually added, and the user needs to manually augment a column of zero-one indicator.\nResponse Y (Exact Case): If both y_1 and y_2 are observed exactly (i.e. the incurred losses are not   censored or truncated), then we can set exact_Y = true in the initialization and fitting function.   In this case, the dimension of Y should be 100 by 2 (= N * D): the first column is for y_1 and   the second for y_2.\nResponse Y (Not Exact Case): If either y_1 or y_2 is not observed exactly, then exact_Y = false and   the dimension of Y should be 100 by 8 (= N * 4D): the first four columns are for y_1 and the   remaining for y_2. For each block of 4 columns, they should be structured as (tl, yl, yu, tu),   corresponding to the lower bound of truncation, lower bound of censoring, upper bound of censoring and   upper bound of truncation, respectively. Some typical cases are listed below:\nBoth y_1 and y_2 are observed exactly: Assume y_1 = 2.0 and y_2 = 3.0, then the first row of Y   should be [0.0 2.0 2.0 Inf 0.0 3.0 3.0 Inf]. Alternatively, we can set exact_Y = true (see the    previous case), and also set the first row of Y as [2.0 3.0].\ny_1 is observed exactly, y_2 is left-truncated at 1.0 but observed exactly (e.g. an insurance deductible):   Assume y_1 = 2.0 and y_2 = 3.0, then the first row of Y should be [0.0 2.0 2.0 Inf 1.0 3.0 3.0 Inf].\ny_1 is observed exactly, y_2 is right-censored at 2.0 (e.g. a payment limit):   Assume y_1 = 2.0 and y_2 = 3.0, then the first row of Y should be [0.0 2.0 2.0 Inf 0.0 2.0 Inf Inf].\ny_1 is observed exactly, y_2 is only observed within a range:   Assume y_1 = 2.0 and y_2 = 3.0, but we only observe 2.5 < y_2 < 3.5,   then the first row of Y should be [0.0 2.0 2.0 Inf 0.0 2.5 3.5 Inf].\nLogit Regression Coefficients α: Assume we would like to fit an LRMoE with three latent classes (g = 3), then   the dimension of α should be 5 by 3 (= N * g). For example, a noninformative guess can be    initialized as α = fill(0.0, 5, 3).\nComponent Distribution comp_dist: Assume we would like to fit an LRMoE with three lateht classes (g = 3), then   the dimension of comp_dist should be 2 by 3 (= D * g). For example, if we assume y_1 is a mixture of lognormals   and y_2 is a mixture of gammas, then comp_dist = [LogNormalExpert(1.0, 2.0) LogNormalExpert(1.5, 2.5) LogNormalExpert(2.0, 3.0); GammaExpert(1.0, 2.0) GammaExpert(1.5, 2.5) GammaExpert(2.0, 3.0)]. Note that the columns of comp_dist should be   distinct, otherwise the model is not identifiable.\nPenalty on Logit Regression Coefficients pen_α: It should be a single number (i.e. a uniform penalty imposed on    all coefficients in α). For example, when pen_α = 2.0, then the penalty sum( (α ./ 2.0).^2 ) is subtracted   from the loglikelihood as a penalty. In other words, we would not like the magnitude of α to be too large.\nPenalty on Parameters of Expert Functions pen_params: Using the comp_dist mentioned above, pen_params should be   a matrix of size 2 by 3 (= D * g), where each entry is a vector of real numbers penalizing the parameters of   expert functions. Usually, the user can leave this argument as default. For more details, the user is referred to the package source code.","category":"page"},{"location":"dummytest/#Dummy","page":"Dummy","title":"Dummy","text":"","category":"section"},{"location":"dummytest/","page":"Dummy","title":"Dummy","text":"dummy","category":"page"},{"location":"predictive/#Predictive-Functions","page":"Predictive Functions","title":"Predictive Functions","text":"","category":"section"},{"location":"predictive/","page":"Predictive Functions","title":"Predictive Functions","text":"After fitting an LRMoE model, the following predictive functions provide further insights into the dataset. These functions start with predict_ followed by a quantity of interest (e.g. mean_) listed below.","category":"page"},{"location":"predictive/","page":"Predictive Functions","title":"Predictive Functions","text":"class: latent class probabilities and the most likely latent class;\nmean: mean of response;\nvar: variance of response;\nlimit: limited expected value (LEV) of response, that is, Emin(Y d);\nexcess: expected excess value of response, that is, Emax(Y-d 0); and\nVaRCTE: quantile (or Value-at-Risk/VaR) and conditional tail expectation (CTE, or tail-VaR/TVaR) of response.","category":"page"},{"location":"predictive/","page":"Predictive Functions","title":"Predictive Functions","text":"These quantities can be calculated based on either the prior and posterior latent class probabilities, as indicated by the suffix of these functions.","category":"page"},{"location":"predictive/","page":"Predictive Functions","title":"Predictive Functions","text":"prior: the latent class probabilities are based on the covariates X and logit regression coefficients α.\nposterior: the latent class probabilities are based on the covariates X, logit regression coefficients α and observed values Y.","category":"page"},{"location":"predictive/","page":"Predictive Functions","title":"Predictive Functions","text":"The differences of these probabilities can be found in Fung et al. (2019).","category":"page"},{"location":"predictive/","page":"Predictive Functions","title":"Predictive Functions","text":"The following contains a detailed description of all predictive functions included in the package. Throughout this page, Y is a matrix of response, X a matrix of covariates, α a matrix of logit regression coefficients and model a matrix of expert functions.","category":"page"},{"location":"predictive/","page":"Predictive Functions","title":"Predictive Functions","text":"predict_class_prior\npredict_class_posterior\npredict_mean_prior\npredict_mean_posterior\npredict_var_prior\npredict_var_posterior\npredict_limit_prior\npredict_limit_posterior\npredict_excess_prior\npredict_excess_posterior\npredict_VaRCTE_prior\npredict_VaRCTE_posterior","category":"page"},{"location":"predictive/#LRMoE.predict_class_prior","page":"Predictive Functions","title":"LRMoE.predict_class_prior","text":"predict_class_prior(X, α)\n\nPredicts the latent class probabilities,  given covariates X  and logit regression coefficients α.\n\nArguments\n\nX: A matrix of covariates.\nα: A matrix of logit regression coefficients.\n\nReturn Values\n\nprob: A matrix of latent class probabilities.\nmax_prob_idx: A matrix of the most likely latent class for each observation.\n\n\n\n\n\n","category":"function"},{"location":"predictive/#LRMoE.predict_class_posterior","page":"Predictive Functions","title":"LRMoE.predict_class_posterior","text":"predict_class_posterior(Y, X, α, model; \n    exact_Y = true, exposure_past = nothing)\n\nPredicts the latent class probabilities,  given observations Y, covariates X,  logit regression coefficients α and a specified model of expert functions. \n\nArguments\n\nY: A matrix of responses.\nX: A matrix of covariates.\nα: A matrix of logit regression coefficients.\nmodel: A matrix specifying the expert functions.\n\nOptional Arguments\n\nexact_Y: true or false (default), indicating if Y is observed exactly or with censoring and truncation.\nexposure_past: A vector indicating the time exposure (past) of each observation. If nothing is supplied, it is set to 1.0 by default.\n\nReturn Values\n\nprob: A matrix of latent class probabilities.\nmax_prob_idx: A matrix of the most likely latent class for each observation.\n\n\n\n\n\n","category":"function"},{"location":"predictive/#LRMoE.predict_mean_prior","page":"Predictive Functions","title":"LRMoE.predict_mean_prior","text":"predict_mean_prior(X, α, model; \n    exposure_future = nothing)\n\nPredicts the mean values of response,  given covariates X,  logit regression coefficients α and a specified model of expert functions.\n\nArguments\n\nX: A matrix of covariates.\nα: A matrix of logit regression coefficients.\nmodel: A matrix specifying the expert functions.\n\nOptional Arguments\n\nexposure_future: A vector indicating the time exposure (future) of each observation. If nothing is supplied, it is set to 1.0 by default.\n\nReturn Values\n\nA matrix of predicted mean values of response, based on prior probabilities.\n\n\n\n\n\n","category":"function"},{"location":"predictive/#LRMoE.predict_mean_posterior","page":"Predictive Functions","title":"LRMoE.predict_mean_posterior","text":"predict_mean_posterior(Y, X, α, model; \n    exact_Y = true, exposure_past = nothing, exposure_future = nothing)\n\nPredicts the mean values of response, given observations Y, covariates X,  logit regression coefficients α and a specified model of expert functions.\n\nArguments\n\nY: A matrix of responses.\nX: A matrix of covariates.\nα: A matrix of logit regression coefficients.\nmodel: A matrix specifying the expert functions.\n\nOptional Arguments\n\nexact_Y: true or false (default), indicating if Y is observed exactly or with censoring and truncation.\nexposure_past: A vector indicating the time exposure (past) of each observation. If nothing is supplied, it is set to 1.0 by default.\nexposure_future: A vector indicating the time exposure (future) of each observation. If nothing is supplied, it is set to 1.0 by default.\n\nReturn Values\n\nA matrix of predicted mean values of response, based on posterior probabilities.\n\n\n\n\n\n","category":"function"},{"location":"predictive/#LRMoE.predict_var_prior","page":"Predictive Functions","title":"LRMoE.predict_var_prior","text":"predict_var_prior(X, α, model; \n    exposure_future = nothing)\n\nPredicts the variance of response,  given covariates X,  logit regression coefficients α and a specified model of expert functions.\n\nArguments\n\nX: A matrix of covariates.\nα: A matrix of logit regression coefficients.\nmodel: A matrix specifying the expert functions.\n\nOptional Arguments\n\nexposure_future: A vector indicating the time exposure of each observation. If nothing is supplied, it is set to 1.0 by default.\n\nReturn Values\n\nA matrix of predicted variance of response, based on prior probabilities.\n\n\n\n\n\n","category":"function"},{"location":"predictive/#LRMoE.predict_var_posterior","page":"Predictive Functions","title":"LRMoE.predict_var_posterior","text":"predict_var_posterior(Y, X, α, model; \n    exact_Y = true, exposure_past = nothing, exposure_future = nothing)\n\nPredicts the variance of response,  given observations Y, covariates X,  logit regression coefficients α and a specified model of expert functions.\n\nArguments\n\nY: A matrix of responses.\nX: A matrix of covariates.\nα: A matrix of logit regression coefficients.\nmodel: A matrix specifying the expert functions.\n\nOptional Arguments\n\nexact_Y: true or false (default), indicating if Y is observed exactly or with censoring and truncation.\nexposure_past: A vector indicating the time exposure (past) of each observation. If nothing is supplied, it is set to 1.0 by default.\nexposure_future: A vector indicating the time exposure (future) of each observation. If nothing is supplied, it is set to 1.0 by default.\n\nReturn Values\n\nA matrix of predicted variance of response, based on posterior probabilities.\n\n\n\n\n\n","category":"function"},{"location":"predictive/#LRMoE.predict_limit_prior","page":"Predictive Functions","title":"LRMoE.predict_limit_prior","text":"predict_limit_prior(X, α, model, limit; \n    exposure_future = nothing)\n\nPredicts the limit expected value (LEV) of response,  given covariates X,  logit regression coefficients α and a specified model of expert functions.\n\nArguments\n\nX: A matrix of covariates.\nα: A matrix of logit regression coefficients.\nmodel: A matrix specifying the expert functions.\nlimit: A matrix specifying the cutoff point.\n\nOptional Arguments\n\nexposure_future: A vector indicating the time exposure (future) of each observation. If nothing is supplied, it is set to 1.0 by default.\n\nReturn Values\n\nA matrix of predicted limit expected value of response, based on prior probabilities.\n\n\n\n\n\n","category":"function"},{"location":"predictive/#LRMoE.predict_limit_posterior","page":"Predictive Functions","title":"LRMoE.predict_limit_posterior","text":"predict_limit_posterior(Y, X, α, model, limit;\n    exact_Y = true, exposure_past = nothing, exposure_future = nothing)\n\nPredicts the limit expected value (LEV) of response,  given observations Y, covariates X,  logit regression coefficients α and a specified model of expert functions.\n\nArguments\n\nY: A matrix of responses.\nX: A matrix of covariates.\nα: A matrix of logit regression coefficients.\nmodel: A matrix specifying the expert functions.\nlimit: A vector specifying the cutoff point.\n\nOptional Arguments\n\nexact_Y: true or false (default), indicating if Y is observed exactly or with censoring and truncation.\nexposure_past: A vector indicating the time exposure (past) of each observation. If nothing is supplied, it is set to 1.0 by default.\nexposure_future: A vector indicating the time exposure (future) of each observation. If nothing is supplied, it is set to 1.0 by default.\n\nReturn Values\n\nA matrix of predicted limit expected value of response, based on posterior probabilities.\n\n\n\n\n\n","category":"function"},{"location":"predictive/#LRMoE.predict_excess_prior","page":"Predictive Functions","title":"LRMoE.predict_excess_prior","text":"predict_excess_prior(X, α, model, limit;\n    exposure_future = nothing)\n\nPredicts the excess expectation of response,  given covariates X,  logit regression coefficients α and a specified model of expert functions.\n\nArguments\n\nX: A matrix of covariates.\nα: A matrix of logit regression coefficients.\nmodel: A matrix specifying the expert functions.\nlimit: A vector specifying the cutoff point.\n\nOptional Arguments\n\nexposure_future: A vector indicating the time exposure (future) of each observation. If nothing is supplied, it is set to 1.0 by default.\n\nReturn Values\n\nA matrix of predicted excess expectation of response, based on prior probabilities.\n\n\n\n\n\n","category":"function"},{"location":"predictive/#LRMoE.predict_excess_posterior","page":"Predictive Functions","title":"LRMoE.predict_excess_posterior","text":"predict_excess_posterior(Y, X, α, model, limit;\n    exact_Y = true, exposure_past = nothing, exposure_future = nothing)\n\nPredicts the excess expectation of response,  given observations Y, covariates X,  logit regression coefficients α and a specified model of expert functions.\n\nArguments\n\nY: A matrix of responses.\nX: A matrix of covariates.\nα: A matrix of logit regression coefficients.\nmodel: A matrix specifying the expert functions.\nlimit: A vector specifying the cutoff point.\n\nOptional Arguments\n\nexact_Y: true or false (default), indicating if Y is observed exactly or with censoring and truncation.\nexposure_past: A vector indicating the time exposure (past) of each observation. If nothing is supplied, it is set to 1.0 by default.\nexposure_future: A vector indicating the time exposure (future) of each observation. If nothing is supplied, it is set to 1.0 by default.\n\nReturn Values\n\nA matrix of predicted excess expectation of response, based on posterior probabilities.\n\n\n\n\n\n","category":"function"},{"location":"predictive/#LRMoE.predict_VaRCTE_prior","page":"Predictive Functions","title":"LRMoE.predict_VaRCTE_prior","text":"predict_VaRCTE_prior(X, α, model, p;\n    exposure_future = nothing)\n\nPredicts the p-th value-at-risk (VaR) and conditional tail expectation (CTE) of response,  given covariates X,  logit regression coefficients α and a specified model of expert functions.\n\nArguments\n\nX: A matrix of covariates.\nα: A matrix of logit regression coefficients.\nmodel: A matrix specifying the expert functions.\np: A matrix of probabilities.\n\nOptional Arguments\n\nexposure_future: A vector indicating the time exposure (future) of each observation. If nothing is supplied, it is set to 1.0 by default.\n\nReturn Values\n\nVaR: A matrix of predicted VaR of response, based on prior probabilities.\nCTE: A matrix of predicted CTE of response, based on prior probabilities.\n\n\n\n\n\n","category":"function"},{"location":"predictive/#LRMoE.predict_VaRCTE_posterior","page":"Predictive Functions","title":"LRMoE.predict_VaRCTE_posterior","text":"predict_VaRCTE_posterior(Y, X, α, model, p;\n    exact_Y = true, exposure_past = nothing, exposure_future = nothing)\n\nPredicts the p-th value-at-risk (VaR) and conditional tail expectation (CTE) of response,  given observations Y, covariates X, logit regression coefficients α and a specified model of expert functions.\n\nArguments\n\nX: A matrix of covariates.\nα: A matrix of logit regression coefficients.\nmodel: A matrix specifying the expert functions.\np: A matrix of probabilities.\n\nOptional Arguments\n\nexact_Y: true or false (default), indicating if Y is observed exactly or with censoring and truncation.\nexposure_past: A vector indicating the time exposure (past) of each observation. If nothing is supplied, it is set to 1.0 by default.\nexposure_future: A vector indicating the time exposure (future) of each observation. If nothing is supplied, it is set to 1.0 by default.\n\nReturn Values\n\nVaR: A matrix of predicted VaR of response, based on posterior probabilities.\nCTE: A matrix of predicted CTE of response, based on posterior probabilities.\n\n\n\n\n\n","category":"function"},{"location":"#LRMoE-Package","page":"Overview","title":"LRMoE Package","text":"","category":"section"},{"location":"","page":"Overview","title":"Overview","text":"LRMoE is a package tailor-made for actuarial applications which allows actuarial researchers and practitioners to model and analyze insurance loss frequencies and severities using the Logit-weighted Reduced Mixture-of-Experts (LRMoE) model. The flexibility of LRMoE models is theoretically justified in Fung et al. (2019), and an application of LRMoE for modelling correlated insurance claim frequencies is in Fung et al. (2019).","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"The package LRMoE offers several new distinctive features which are motivated by various actuarial applications and mostly cannot be achieved using existing packages for mixture models. Key features include:","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"A wider coverage on frequency and severity distributions and their zero inflation;\nThe flexibility to vary classes of distributions across components;\nParameter estimation under data censoring and truncation;\nA collection of insurance rate making and reserving functions; and\nModel selection and visualization tools.","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"While LRMoE was initially developed for actuarial application, this package also allows for customized expert functions for various modelling problems outside of the insurance context. For more details, see here.","category":"page"}]
}
